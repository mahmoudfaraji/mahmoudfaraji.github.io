---
layout: archive
title: "Others"
permalink: /others/
author_profile: true
---


<a href="/others"  class='header-color'>Research Experiences</a>
---------
### APA AUT CERT (<a href="https://apa.aut.ac.ir/en" target="_Blank">https://apa.aut.ac.ir/en</a>):
<ul class='onecol' markdown='1'>
<li> Research Assistant at AUT CERT Lab. - (<i style='font-size: 0.8em;'>June 2021 - Now (In Progress) </i>)</li>
<p style='text-align: justify;'> Web Application Security Analysis With Prof. <a href="https://aut.ac.ir/cv/2102/%d8%a8%d8%a7%d8%a8%da%a9%20%d8%b5%d8%a7%d8%af%d9%82%db%8c%d8%a7%d9%86" target="_Blank">Babak Sadeghiyan</a></p>
<p style='text-align: justify;'> In this lab, we examine the security vulnerabilities of web and mobile applications and we provide awareness to business owners of the existence of security bugs that we have identified based on the OWASP standard and for improve and fix this vulnerabilities give them advice.</p>
</ul>

### Amirkabir University of Technology (Tehran Polytechnic) (AUT): 
<ul class='onecol' markdown='1'>
<li> Research Assistant at Security Analysis Lab. - (<i style='font-size: 0.8em;'>Sep. 2021 - Nov. 2022 (Expected) (In Progress) </i>)</li>
<p style='text-align: justify;'> "A Method for Protecting Privacy of IoT Healthcare Data Against Machine Learning Attack" M.Sc. Thesis with Prof. <a href="https://aut.ac.ir/~shahriari" target="_Blank">Hamid Reza Shahriari</a></p>
<p style='text-align: justify;'> Machine learning models leak information about the individual data records on which they were trained. <a href="https://www.comp.nus.edu.sg/~reza/" target="_Blank">Reza Shokri</a> et al.[<a href="#Ref_1">1</a>] focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, they make adversarial use of machine learning and train their own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. They empirically evaluate their inference techniques on classification models trained by commercial "machine learning as a service" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, they show that these models can be vulnerable to membership inference attacks. So, in this lab we are looking for find a way for protect from healthcare data privacy in iot which causes the data to be stored anonymously and enter the training stage of machine learning algorithms so that these machine learning algorithms do not understand the original data. Also this solution must be lightweight for IoT environment.</p>
</ul>

<p style='padding-left: 30px;'>
<img style='border: 3px solid #111;width: 600px;' alt="Membership Inference Attack" src="/images/membership inference attack.png">
<h3 style='padding-left: 30px;font-size: 0.6em;'> Picture Reference = [<a href="#Ref_2">2</a>]</h3>
</p>

### Islamic Azad University (South Tehran Branch):
<ul class='onecol' markdown='1'>
<li> Programming Language (<i style='font-size: 0.9em;'>Instuctor</i>), 2019</li>
</ul>


<a style='font-size: 0.7em;' href="#" class='header-color'>References</a>
--------
<div style='font-size: 0.6em;'>
<p id="Ref_1">
[1].<a href="https://ieeexplore.ieee.org/abstract/document/7958568" target="_Blank">https://ieeexplore.ieee.org/abstract/document/7958568</a>
</p>
<p id="Ref_2">
[2].<a href="https://ieeexplore.ieee.org/abstract/document/8634878" target="_Blank">https://ieeexplore.ieee.org/abstract/document/8634878</a>
</p>
</div>

